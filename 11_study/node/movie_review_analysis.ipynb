{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb102df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a21e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f1eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68fe28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1607162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413b3f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f49ed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed47818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4edef00",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77/2733197300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. = embedding은 각 문장의 길이가 똑같아야하는데 4,4,5 여서\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa03729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1d7cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.00015259 -0.00319766 -0.01053388 -0.0442904 ]\n",
      "  [-0.04233989  0.0142988   0.03808876  0.00927172]\n",
      "  [ 0.03624929 -0.03268826 -0.01503922 -0.0252395 ]\n",
      "  [-0.0186473  -0.02898846  0.00941596  0.04877791]\n",
      "  [ 0.01874072 -0.04203688  0.02331725 -0.02738379]]\n",
      "\n",
      " [[-0.00015259 -0.00319766 -0.01053388 -0.0442904 ]\n",
      "  [-0.04233989  0.0142988   0.03808876  0.00927172]\n",
      "  [-0.00598862  0.04830022 -0.00796522  0.02725055]\n",
      "  [-0.03185402  0.00210903  0.00500231  0.03700087]\n",
      "  [ 0.01874072 -0.04203688  0.02331725 -0.02738379]]\n",
      "\n",
      " [[-0.00015259 -0.00319766 -0.01053388 -0.0442904 ]\n",
      "  [ 0.01191849  0.02291553  0.02494698 -0.04112653]\n",
      "  [-0.04233989  0.0142988   0.03808876  0.00927172]\n",
      "  [ 0.03624929 -0.03268826 -0.01503922 -0.0252395 ]\n",
      "  [ 0.00738437  0.00461765  0.03075508 -0.00337807]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2484a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d7737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN \n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a25e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c15c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75a72926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ad8dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b23c164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ef13d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e146389a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b593329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c333f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bf8ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58e845c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70361311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 26s 46ms/step - loss: 0.6931 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5012\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6928 - accuracy: 0.5114 - val_loss: 0.6930 - val_accuracy: 0.5012\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6922 - accuracy: 0.5120 - val_loss: 0.6927 - val_accuracy: 0.5014\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6904 - accuracy: 0.5103 - val_loss: 0.6911 - val_accuracy: 0.5045\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.7000 - accuracy: 0.5313 - val_loss: 0.6926 - val_accuracy: 0.5075\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6934 - val_accuracy: 0.5019\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6898 - accuracy: 0.5251 - val_loss: 0.6925 - val_accuracy: 0.5046\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6879 - accuracy: 0.5295 - val_loss: 0.6915 - val_accuracy: 0.5067\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6853 - accuracy: 0.5313 - val_loss: 0.6900 - val_accuracy: 0.5088\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6822 - accuracy: 0.5309 - val_loss: 0.6887 - val_accuracy: 0.5074\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6801 - accuracy: 0.5303 - val_loss: 0.6887 - val_accuracy: 0.5073\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6782 - accuracy: 0.5327 - val_loss: 0.6883 - val_accuracy: 0.5082\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6761 - accuracy: 0.5345 - val_loss: 0.6879 - val_accuracy: 0.5091\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6739 - accuracy: 0.5362 - val_loss: 0.6874 - val_accuracy: 0.5110\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6715 - accuracy: 0.5371 - val_loss: 0.6879 - val_accuracy: 0.5105\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6690 - accuracy: 0.5380 - val_loss: 0.6880 - val_accuracy: 0.5109\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6665 - accuracy: 0.5387 - val_loss: 0.6886 - val_accuracy: 0.5120\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6640 - accuracy: 0.5395 - val_loss: 0.6879 - val_accuracy: 0.5143\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6612 - accuracy: 0.5401 - val_loss: 0.6862 - val_accuracy: 0.5155\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6586 - accuracy: 0.5413 - val_loss: 0.6836 - val_accuracy: 0.5179\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1566fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.6845 - accuracy: 0.5194\n",
      "[0.684454619884491, 0.5193600058555603]\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6844de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a73797e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ae47ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10615d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fa1f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = '/aiffel/aiffel/workspace/11_study/node/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74e15618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02273662, -0.03778426, -0.01135581,  0.02171756, -0.02470951,\n",
       "       -0.08038092, -0.05663408,  0.09162321,  0.02811592,  0.00673239,\n",
       "        0.05612374, -0.04041625, -0.00359284, -0.0270534 ,  0.05760284,\n",
       "        0.06326819], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df258b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('most', 0.9400350451469421),\n",
       " ('feel', 0.9355340600013733),\n",
       " ('events', 0.9267721772193909),\n",
       " ('romance', 0.9251225590705872),\n",
       " ('lets', 0.923139750957489),\n",
       " ('final', 0.922500491142273),\n",
       " ('life', 0.9221886396408081),\n",
       " ('christian', 0.9214330911636353),\n",
       " ('believe', 0.9103080034255981),\n",
       " ('somewhat', 0.9061732292175293)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee36d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google wordvector 링크\n",
    "!ln -s ~/data/GoogleNews-vectors-negative300.bin.gz /aiffel/aiffel/workspace/11_study/node/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24a8dff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = '/aiffel/aiffel/workspace/11_study/node/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000) # 300만개중 100만개만 limit\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be0f2290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6202cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6c25b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35d3e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 17s 90ms/step - loss: 0.6954 - accuracy: 0.5379 - val_loss: 0.6743 - val_accuracy: 0.5876\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6444 - accuracy: 0.6498 - val_loss: 0.6185 - val_accuracy: 0.6865\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.5550 - accuracy: 0.7353 - val_loss: 0.4999 - val_accuracy: 0.7900\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.4079 - accuracy: 0.8404 - val_loss: 0.3889 - val_accuracy: 0.8351\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.2968 - accuracy: 0.8848 - val_loss: 0.3636 - val_accuracy: 0.8370\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.2309 - accuracy: 0.9134 - val_loss: 0.3115 - val_accuracy: 0.8677\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 83ms/step - loss: 0.1779 - accuracy: 0.9401 - val_loss: 0.3040 - val_accuracy: 0.8740\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.1336 - accuracy: 0.9607 - val_loss: 0.3076 - val_accuracy: 0.8697\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.1048 - accuracy: 0.9726 - val_loss: 0.3139 - val_accuracy: 0.8713\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0808 - accuracy: 0.9824 - val_loss: 0.3237 - val_accuracy: 0.8698\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0598 - accuracy: 0.9899 - val_loss: 0.3384 - val_accuracy: 0.8704\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0447 - accuracy: 0.9946 - val_loss: 0.3635 - val_accuracy: 0.8650\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0321 - accuracy: 0.9971 - val_loss: 0.3701 - val_accuracy: 0.8695\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0236 - accuracy: 0.9985 - val_loss: 0.3859 - val_accuracy: 0.8681\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0178 - accuracy: 0.9992 - val_loss: 0.4006 - val_accuracy: 0.8684\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0140 - accuracy: 0.9995 - val_loss: 0.4173 - val_accuracy: 0.8653\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0114 - accuracy: 0.9995 - val_loss: 0.4268 - val_accuracy: 0.8673\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 0.4376 - val_accuracy: 0.8673\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.4497 - val_accuracy: 0.8667\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.4605 - val_accuracy: 0.8654\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d18f9494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.4866 - accuracy: 0.8614\n",
      "[0.48662278056144714, 0.8614400029182434]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21fda3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
